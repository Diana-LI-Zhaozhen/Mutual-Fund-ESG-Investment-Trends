{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from installdatabase import *\n",
    "import pickle\n",
    "\n",
    "path = r'C:\\Users\\zhaoz\\Desktop\\bigdata\\finalproject\\data'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get related issues and topics of reprisk_new."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 0 days 00:00:00.004399 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected Http Driver Exception\n"
     ]
    },
    {
     "ename": "OperationalError",
     "evalue": "Error HTTPConnectionPool(host='localhost', port=8123): Max retries exceeded with url: /?wait_end_of_query=1 (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000183658BB3A0>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it')) executing HTTP request http://localhost:8123",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mConnectionRefusedError\u001b[0m                    Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\zhaoz\\anaconda3\\envs\\Pytorch\\lib\\site-packages\\urllib3\\connection.py:200\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    199\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 200\u001b[0m     sock \u001b[39m=\u001b[39m connection\u001b[39m.\u001b[39;49mcreate_connection(\n\u001b[0;32m    201\u001b[0m         (\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dns_host, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mport),\n\u001b[0;32m    202\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtimeout,\n\u001b[0;32m    203\u001b[0m         source_address\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msource_address,\n\u001b[0;32m    204\u001b[0m         socket_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msocket_options,\n\u001b[0;32m    205\u001b[0m     )\n\u001b[0;32m    206\u001b[0m \u001b[39mexcept\u001b[39;00m socket\u001b[39m.\u001b[39mgaierror \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\zhaoz\\anaconda3\\envs\\Pytorch\\lib\\site-packages\\urllib3\\util\\connection.py:85\u001b[0m, in \u001b[0;36mcreate_connection\u001b[1;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[0;32m     84\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 85\u001b[0m     \u001b[39mraise\u001b[39;00m err\n\u001b[0;32m     86\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     87\u001b[0m     \u001b[39m# Break explicitly a reference cycle\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\zhaoz\\anaconda3\\envs\\Pytorch\\lib\\site-packages\\urllib3\\util\\connection.py:73\u001b[0m, in \u001b[0;36mcreate_connection\u001b[1;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[0;32m     72\u001b[0m     sock\u001b[39m.\u001b[39mbind(source_address)\n\u001b[1;32m---> 73\u001b[0m sock\u001b[39m.\u001b[39;49mconnect(sa)\n\u001b[0;32m     74\u001b[0m \u001b[39m# Break explicitly a reference cycle\u001b[39;00m\n",
      "\u001b[1;31mConnectionRefusedError\u001b[0m: [WinError 10061] No connection could be made because the target machine actively refused it",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mNewConnectionError\u001b[0m                        Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\zhaoz\\anaconda3\\envs\\Pytorch\\lib\\site-packages\\urllib3\\connectionpool.py:790\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[0;32m    789\u001b[0m \u001b[39m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[1;32m--> 790\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_make_request(\n\u001b[0;32m    791\u001b[0m     conn,\n\u001b[0;32m    792\u001b[0m     method,\n\u001b[0;32m    793\u001b[0m     url,\n\u001b[0;32m    794\u001b[0m     timeout\u001b[39m=\u001b[39mtimeout_obj,\n\u001b[0;32m    795\u001b[0m     body\u001b[39m=\u001b[39mbody,\n\u001b[0;32m    796\u001b[0m     headers\u001b[39m=\u001b[39mheaders,\n\u001b[0;32m    797\u001b[0m     chunked\u001b[39m=\u001b[39mchunked,\n\u001b[0;32m    798\u001b[0m     retries\u001b[39m=\u001b[39mretries,\n\u001b[0;32m    799\u001b[0m     response_conn\u001b[39m=\u001b[39mresponse_conn,\n\u001b[0;32m    800\u001b[0m     preload_content\u001b[39m=\u001b[39mpreload_content,\n\u001b[0;32m    801\u001b[0m     decode_content\u001b[39m=\u001b[39mdecode_content,\n\u001b[0;32m    802\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mresponse_kw,\n\u001b[0;32m    803\u001b[0m )\n\u001b[0;32m    805\u001b[0m \u001b[39m# Everything went great!\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\zhaoz\\anaconda3\\envs\\Pytorch\\lib\\site-packages\\urllib3\\connectionpool.py:496\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[0;32m    495\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 496\u001b[0m     conn\u001b[39m.\u001b[39;49mrequest(\n\u001b[0;32m    497\u001b[0m         method,\n\u001b[0;32m    498\u001b[0m         url,\n\u001b[0;32m    499\u001b[0m         body\u001b[39m=\u001b[39;49mbody,\n\u001b[0;32m    500\u001b[0m         headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[0;32m    501\u001b[0m         chunked\u001b[39m=\u001b[39;49mchunked,\n\u001b[0;32m    502\u001b[0m         preload_content\u001b[39m=\u001b[39;49mpreload_content,\n\u001b[0;32m    503\u001b[0m         decode_content\u001b[39m=\u001b[39;49mdecode_content,\n\u001b[0;32m    504\u001b[0m         enforce_content_length\u001b[39m=\u001b[39;49menforce_content_length,\n\u001b[0;32m    505\u001b[0m     )\n\u001b[0;32m    507\u001b[0m \u001b[39m# We are swallowing BrokenPipeError (errno.EPIPE) since the server is\u001b[39;00m\n\u001b[0;32m    508\u001b[0m \u001b[39m# legitimately able to close the connection after sending a valid response.\u001b[39;00m\n\u001b[0;32m    509\u001b[0m \u001b[39m# With this behaviour, the received response is still readable.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\zhaoz\\anaconda3\\envs\\Pytorch\\lib\\site-packages\\urllib3\\connection.py:388\u001b[0m, in \u001b[0;36mHTTPConnection.request\u001b[1;34m(self, method, url, body, headers, chunked, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[0;32m    387\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mputheader(header, value)\n\u001b[1;32m--> 388\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mendheaders()\n\u001b[0;32m    390\u001b[0m \u001b[39m# If we're given a body we start sending that in chunks.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\zhaoz\\anaconda3\\envs\\Pytorch\\lib\\http\\client.py:1277\u001b[0m, in \u001b[0;36mHTTPConnection.endheaders\u001b[1;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[0;32m   1276\u001b[0m     \u001b[39mraise\u001b[39;00m CannotSendHeader()\n\u001b[1;32m-> 1277\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_send_output(message_body, encode_chunked\u001b[39m=\u001b[39;49mencode_chunked)\n",
      "File \u001b[1;32mc:\\Users\\zhaoz\\anaconda3\\envs\\Pytorch\\lib\\http\\client.py:1037\u001b[0m, in \u001b[0;36mHTTPConnection._send_output\u001b[1;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[0;32m   1036\u001b[0m \u001b[39mdel\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_buffer[:]\n\u001b[1;32m-> 1037\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msend(msg)\n\u001b[0;32m   1039\u001b[0m \u001b[39mif\u001b[39;00m message_body \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   1040\u001b[0m \n\u001b[0;32m   1041\u001b[0m     \u001b[39m# create a consistent interface to message_body\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\zhaoz\\anaconda3\\envs\\Pytorch\\lib\\http\\client.py:975\u001b[0m, in \u001b[0;36mHTTPConnection.send\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    974\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mauto_open:\n\u001b[1;32m--> 975\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconnect()\n\u001b[0;32m    976\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\zhaoz\\anaconda3\\envs\\Pytorch\\lib\\site-packages\\urllib3\\connection.py:236\u001b[0m, in \u001b[0;36mHTTPConnection.connect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    235\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mconnect\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 236\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msock \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_new_conn()\n\u001b[0;32m    237\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tunnel_host:\n\u001b[0;32m    238\u001b[0m         \u001b[39m# If we're tunneling it means we're connected to our proxy.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\zhaoz\\anaconda3\\envs\\Pytorch\\lib\\site-packages\\urllib3\\connection.py:215\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mOSError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m--> 215\u001b[0m     \u001b[39mraise\u001b[39;00m NewConnectionError(\n\u001b[0;32m    216\u001b[0m         \u001b[39mself\u001b[39m, \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mFailed to establish a new connection: \u001b[39m\u001b[39m{\u001b[39;00me\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    217\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n\u001b[0;32m    219\u001b[0m \u001b[39mreturn\u001b[39;00m sock\n",
      "\u001b[1;31mNewConnectionError\u001b[0m: <urllib3.connection.HTTPConnection object at 0x00000183658BB3A0>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mMaxRetryError\u001b[0m                             Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\zhaoz\\anaconda3\\envs\\Pytorch\\lib\\site-packages\\clickhouse_connect\\driver\\httpclient.py:375\u001b[0m, in \u001b[0;36mHttpClient._raw_request\u001b[1;34m(self, data, params, headers, method, retries, stream, server_wait, fields, error_handler)\u001b[0m\n\u001b[0;32m    374\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 375\u001b[0m     response: HTTPResponse \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhttp\u001b[39m.\u001b[39mrequest(method, url, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    376\u001b[0m \u001b[39mexcept\u001b[39;00m HTTPError \u001b[39mas\u001b[39;00m ex:\n",
      "File \u001b[1;32mc:\\Users\\zhaoz\\anaconda3\\envs\\Pytorch\\lib\\site-packages\\urllib3\\_request_methods.py:118\u001b[0m, in \u001b[0;36mRequestMethods.request\u001b[1;34m(self, method, url, body, fields, headers, json, **urlopen_kw)\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 118\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrequest_encode_body(\n\u001b[0;32m    119\u001b[0m         method, url, fields\u001b[39m=\u001b[39mfields, headers\u001b[39m=\u001b[39mheaders, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39murlopen_kw\n\u001b[0;32m    120\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\zhaoz\\anaconda3\\envs\\Pytorch\\lib\\site-packages\\urllib3\\_request_methods.py:217\u001b[0m, in \u001b[0;36mRequestMethods.request_encode_body\u001b[1;34m(self, method, url, fields, headers, encode_multipart, multipart_boundary, **urlopen_kw)\u001b[0m\n\u001b[0;32m    215\u001b[0m extra_kw\u001b[39m.\u001b[39mupdate(urlopen_kw)\n\u001b[1;32m--> 217\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39murlopen(method, url, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mextra_kw)\n",
      "File \u001b[1;32mc:\\Users\\zhaoz\\anaconda3\\envs\\Pytorch\\lib\\site-packages\\urllib3\\poolmanager.py:433\u001b[0m, in \u001b[0;36mPoolManager.urlopen\u001b[1;34m(self, method, url, redirect, **kw)\u001b[0m\n\u001b[0;32m    432\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 433\u001b[0m     response \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39murlopen(method, u\u001b[39m.\u001b[39mrequest_uri, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkw)\n\u001b[0;32m    435\u001b[0m redirect_location \u001b[39m=\u001b[39m redirect \u001b[39mand\u001b[39;00m response\u001b[39m.\u001b[39mget_redirect_location()\n",
      "File \u001b[1;32mc:\\Users\\zhaoz\\anaconda3\\envs\\Pytorch\\lib\\site-packages\\urllib3\\connectionpool.py:874\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[0;32m    871\u001b[0m     log\u001b[39m.\u001b[39mwarning(\n\u001b[0;32m    872\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mRetrying (\u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m) after connection broken by \u001b[39m\u001b[39m'\u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m, retries, err, url\n\u001b[0;32m    873\u001b[0m     )\n\u001b[1;32m--> 874\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39murlopen(\n\u001b[0;32m    875\u001b[0m         method,\n\u001b[0;32m    876\u001b[0m         url,\n\u001b[0;32m    877\u001b[0m         body,\n\u001b[0;32m    878\u001b[0m         headers,\n\u001b[0;32m    879\u001b[0m         retries,\n\u001b[0;32m    880\u001b[0m         redirect,\n\u001b[0;32m    881\u001b[0m         assert_same_host,\n\u001b[0;32m    882\u001b[0m         timeout\u001b[39m=\u001b[39mtimeout,\n\u001b[0;32m    883\u001b[0m         pool_timeout\u001b[39m=\u001b[39mpool_timeout,\n\u001b[0;32m    884\u001b[0m         release_conn\u001b[39m=\u001b[39mrelease_conn,\n\u001b[0;32m    885\u001b[0m         chunked\u001b[39m=\u001b[39mchunked,\n\u001b[0;32m    886\u001b[0m         body_pos\u001b[39m=\u001b[39mbody_pos,\n\u001b[0;32m    887\u001b[0m         preload_content\u001b[39m=\u001b[39mpreload_content,\n\u001b[0;32m    888\u001b[0m         decode_content\u001b[39m=\u001b[39mdecode_content,\n\u001b[0;32m    889\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mresponse_kw,\n\u001b[0;32m    890\u001b[0m     )\n\u001b[0;32m    892\u001b[0m \u001b[39m# Handle redirect?\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\zhaoz\\anaconda3\\envs\\Pytorch\\lib\\site-packages\\urllib3\\connectionpool.py:844\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[0;32m    842\u001b[0m     new_e \u001b[39m=\u001b[39m ProtocolError(\u001b[39m\"\u001b[39m\u001b[39mConnection aborted.\u001b[39m\u001b[39m\"\u001b[39m, new_e)\n\u001b[1;32m--> 844\u001b[0m retries \u001b[39m=\u001b[39m retries\u001b[39m.\u001b[39;49mincrement(\n\u001b[0;32m    845\u001b[0m     method, url, error\u001b[39m=\u001b[39;49mnew_e, _pool\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m, _stacktrace\u001b[39m=\u001b[39;49msys\u001b[39m.\u001b[39;49mexc_info()[\u001b[39m2\u001b[39;49m]\n\u001b[0;32m    846\u001b[0m )\n\u001b[0;32m    847\u001b[0m retries\u001b[39m.\u001b[39msleep()\n",
      "File \u001b[1;32mc:\\Users\\zhaoz\\anaconda3\\envs\\Pytorch\\lib\\site-packages\\urllib3\\util\\retry.py:515\u001b[0m, in \u001b[0;36mRetry.increment\u001b[1;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[0;32m    514\u001b[0m     reason \u001b[39m=\u001b[39m error \u001b[39mor\u001b[39;00m ResponseError(cause)\n\u001b[1;32m--> 515\u001b[0m     \u001b[39mraise\u001b[39;00m MaxRetryError(_pool, url, reason) \u001b[39mfrom\u001b[39;00m \u001b[39mreason\u001b[39;00m  \u001b[39m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m    517\u001b[0m log\u001b[39m.\u001b[39mdebug(\u001b[39m\"\u001b[39m\u001b[39mIncremented Retry for (url=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m): \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m\"\u001b[39m, url, new_retry)\n",
      "\u001b[1;31mMaxRetryError\u001b[0m: HTTPConnectionPool(host='localhost', port=8123): Max retries exceeded with url: /?wait_end_of_query=1 (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000183658BB3A0>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it'))",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m related_issues \u001b[39m=\u001b[39m clickhouse_query(\u001b[39m'''\u001b[39;49m\n\u001b[0;32m      2\u001b[0m \u001b[39mselect distinct related_issues\u001b[39;49m\n\u001b[0;32m      3\u001b[0m \u001b[39mfrom reprisk_new.pm_news_data \u001b[39;49m\n\u001b[0;32m      4\u001b[0m \u001b[39mwhere source_language = \u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mEnglish\u001b[39;49m\u001b[39m'\u001b[39;49m\n\u001b[0;32m      5\u001b[0m \u001b[39mand related_countries_codes = \u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mUS\u001b[39;49m\u001b[39m'\u001b[39;49m\n\u001b[0;32m      6\u001b[0m \u001b[39mand related_issues is not null and related_issues != \u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m'\u001b[39;49m\n\u001b[0;32m      7\u001b[0m \u001b[39m'''\u001b[39;49m)\n\u001b[0;32m      9\u001b[0m related_issues\n",
      "File \u001b[1;32mc:\\Users\\zhaoz\\Desktop\\bigdata\\finalproject\\code\\installdatabase.py:28\u001b[0m, in \u001b[0;36mclickhouse_query\u001b[1;34m(query)\u001b[0m\n\u001b[0;32m     26\u001b[0m elapsed_time \u001b[39m=\u001b[39m end_time \u001b[39m-\u001b[39m start_time\n\u001b[0;32m     27\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mElapsed time: \u001b[39m\u001b[39m{\u001b[39;00melapsed_time\u001b[39m}\u001b[39;00m\u001b[39m seconds\u001b[39m\u001b[39m'\u001b[39m)    \n\u001b[1;32m---> 28\u001b[0m client \u001b[39m=\u001b[39m clickhouse_connect\u001b[39m.\u001b[39;49mget_client(host\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mlocalhost\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m     29\u001b[0m df \u001b[39m=\u001b[39m client\u001b[39m.\u001b[39mquery_df(query)\n\u001b[0;32m     30\u001b[0m \u001b[39mreturn\u001b[39;00m df\n",
      "File \u001b[1;32mc:\\Users\\zhaoz\\anaconda3\\envs\\Pytorch\\lib\\site-packages\\clickhouse_connect\\__init__.py:8\u001b[0m, in \u001b[0;36mget_client\u001b[1;34m(**kwargs)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_client\u001b[39m(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m----> 8\u001b[0m     \u001b[39mreturn\u001b[39;00m create_client(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\zhaoz\\anaconda3\\envs\\Pytorch\\lib\\site-packages\\clickhouse_connect\\driver\\__init__.py:107\u001b[0m, in \u001b[0;36mcreate_client\u001b[1;34m(host, username, password, database, interface, port, secure, dsn, settings, generic_args, **kwargs)\u001b[0m\n\u001b[0;32m    105\u001b[0m                     name \u001b[39m=\u001b[39m name[\u001b[39m3\u001b[39m:]\n\u001b[0;32m    106\u001b[0m                 settings[name] \u001b[39m=\u001b[39m value\n\u001b[1;32m--> 107\u001b[0m     \u001b[39mreturn\u001b[39;00m HttpClient(interface, host, port, username, password, database, settings\u001b[39m=\u001b[39msettings, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    108\u001b[0m \u001b[39mraise\u001b[39;00m ProgrammingError(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mUnrecognized client type \u001b[39m\u001b[39m{\u001b[39;00minterface\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\zhaoz\\anaconda3\\envs\\Pytorch\\lib\\site-packages\\clickhouse_connect\\driver\\httpclient.py:139\u001b[0m, in \u001b[0;36mHttpClient.__init__\u001b[1;34m(self, interface, host, port, username, password, database, compress, query_limit, query_retries, connect_timeout, send_receive_timeout, client_name, verify, ca_cert, client_cert, client_cert_key, session_id, settings, pool_mgr, http_proxy, https_proxy, server_host_name, apply_server_timezone)\u001b[0m\n\u001b[0;32m    136\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    137\u001b[0m     compression \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m--> 139\u001b[0m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(database\u001b[39m=\u001b[39;49mdatabase,\n\u001b[0;32m    140\u001b[0m                  uri\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49murl,\n\u001b[0;32m    141\u001b[0m                  query_limit\u001b[39m=\u001b[39;49mquery_limit,\n\u001b[0;32m    142\u001b[0m                  query_retries\u001b[39m=\u001b[39;49mquery_retries,\n\u001b[0;32m    143\u001b[0m                  server_host_name\u001b[39m=\u001b[39;49mserver_host_name,\n\u001b[0;32m    144\u001b[0m                  apply_server_timezone\u001b[39m=\u001b[39;49mapply_server_timezone)\n\u001b[0;32m    145\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparams \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_settings(ch_settings)\n\u001b[0;32m    146\u001b[0m comp_setting \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_setting_status(\u001b[39m'\u001b[39m\u001b[39menable_http_compression\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\zhaoz\\anaconda3\\envs\\Pytorch\\lib\\site-packages\\clickhouse_connect\\driver\\client.py:57\u001b[0m, in \u001b[0;36mClient.__init__\u001b[1;34m(self, database, query_limit, uri, query_retries, server_host_name, apply_server_timezone)\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mserver_host_name \u001b[39m=\u001b[39m server_host_name\n\u001b[0;32m     55\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mserver_tz \u001b[39m=\u001b[39m pytz\u001b[39m.\u001b[39mUTC\n\u001b[0;32m     56\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mserver_version, server_tz, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdatabase \u001b[39m=\u001b[39m \\\n\u001b[1;32m---> 57\u001b[0m     \u001b[39mtuple\u001b[39m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcommand(\u001b[39m'\u001b[39;49m\u001b[39mSELECT version(), timezone(), currentDatabase()\u001b[39;49m\u001b[39m'\u001b[39;49m, use_database\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m))\n\u001b[0;32m     58\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     59\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mserver_tz \u001b[39m=\u001b[39m pytz\u001b[39m.\u001b[39mtimezone(server_tz)\n",
      "File \u001b[1;32mc:\\Users\\zhaoz\\anaconda3\\envs\\Pytorch\\lib\\site-packages\\clickhouse_connect\\driver\\httpclient.py:308\u001b[0m, in \u001b[0;36mHttpClient.command\u001b[1;34m(self, cmd, parameters, data, settings, use_database)\u001b[0m\n\u001b[0;32m    306\u001b[0m params\u001b[39m.\u001b[39mupdate(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_settings(settings \u001b[39mor\u001b[39;00m {}))\n\u001b[0;32m    307\u001b[0m method \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mPOST\u001b[39m\u001b[39m'\u001b[39m \u001b[39mif\u001b[39;00m payload \u001b[39melse\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mGET\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m--> 308\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_raw_request(payload, params, headers, method)\n\u001b[0;32m    309\u001b[0m result \u001b[39m=\u001b[39m response\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mdecode()[:\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39msplit(\u001b[39m'\u001b[39m\u001b[39m\\t\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m    310\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(result) \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\zhaoz\\anaconda3\\envs\\Pytorch\\lib\\site-packages\\clickhouse_connect\\driver\\httpclient.py:386\u001b[0m, in \u001b[0;36mHttpClient._raw_request\u001b[1;34m(self, data, params, headers, method, retries, stream, server_wait, fields, error_handler)\u001b[0m\n\u001b[0;32m    384\u001b[0m             \u001b[39mcontinue\u001b[39;00m\n\u001b[0;32m    385\u001b[0m     logger\u001b[39m.\u001b[39mwarning(\u001b[39m'\u001b[39m\u001b[39mUnexpected Http Driver Exception\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m--> 386\u001b[0m     \u001b[39mraise\u001b[39;00m OperationalError(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mError \u001b[39m\u001b[39m{\u001b[39;00mex\u001b[39m}\u001b[39;00m\u001b[39m executing HTTP request \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39murl\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m) \u001b[39mfrom\u001b[39;00m \u001b[39mex\u001b[39;00m\n\u001b[0;32m    387\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    388\u001b[0m     \u001b[39mif\u001b[39;00m query_session:\n",
      "\u001b[1;31mOperationalError\u001b[0m: Error HTTPConnectionPool(host='localhost', port=8123): Max retries exceeded with url: /?wait_end_of_query=1 (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000183658BB3A0>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it')) executing HTTP request http://localhost:8123"
     ]
    }
   ],
   "source": [
    "related_issues = clickhouse_query('''\n",
    "select distinct related_issues\n",
    "from reprisk_new.pm_news_data \n",
    "where source_language = 'English'\n",
    "and related_countries_codes = 'US'\n",
    "and related_issues is not null and related_issues != ''\n",
    "''')\n",
    "\n",
    "related_issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 0 days 00:00:00.000950 seconds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>related_topic_tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Salaries and benefits</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Migrant labor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Privacy violations;Cyberattack</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Privacy violations</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Negligence;Migrant labor;Racism/Racial inequality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1195</th>\n",
       "      <td>Coal-fired power plants;Airborne pollutants;Wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1196</th>\n",
       "      <td>Asbestos;Economic impact</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1197</th>\n",
       "      <td>Access to products and services;Epidemics/Pand...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1198</th>\n",
       "      <td>Gender inequality;Epidemics/Pandemics;Racism/R...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1199</th>\n",
       "      <td>Land grabbing;Greenhouse gas (GHG) emissions;L...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1200 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     related_topic_tags\n",
       "0                                 Salaries and benefits\n",
       "1                                         Migrant labor\n",
       "2                        Privacy violations;Cyberattack\n",
       "3                                    Privacy violations\n",
       "4     Negligence;Migrant labor;Racism/Racial inequality\n",
       "...                                                 ...\n",
       "1195  Coal-fired power plants;Airborne pollutants;Wa...\n",
       "1196                           Asbestos;Economic impact\n",
       "1197  Access to products and services;Epidemics/Pand...\n",
       "1198  Gender inequality;Epidemics/Pandemics;Racism/R...\n",
       "1199  Land grabbing;Greenhouse gas (GHG) emissions;L...\n",
       "\n",
       "[1200 rows x 1 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "related_topic_tags = clickhouse_query('''\n",
    "select distinct related_topic_tags\n",
    "from reprisk_new.pm_news_data \n",
    "where source_language = 'English'\n",
    "and related_countries_codes = 'US'\n",
    "and related_topic_tags is not null and related_topic_tags != ''\n",
    "''')\n",
    "\n",
    "related_topic_tags"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Ref:* </br>\n",
    "https://www.reprisk.com/media/pages/static/2134873099-1683183913/rr-data-feeds-and-exports-guidance-on-data-elements_aws.pdf \n",
    "https://www.reprisk.com/news-research/resources/methodology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lower case all characters\n",
    "#remove special characters\n",
    "def get_items(target_string_list):\n",
    "    items = []\n",
    "    for i in target_string_list:\n",
    "        lower_i = str.lower(i)\n",
    "        splited_text = re.split(';', lower_i)\n",
    "        items.append(splited_text)\n",
    "    \n",
    "    unique_items = []\n",
    "\n",
    "    for i in items:\n",
    "        for item in i:\n",
    "            if item not in unique_items:\n",
    "                unique_items.append(item)\n",
    "    \n",
    "    return unique_items\n",
    "\n",
    "cleaned_related_issues = get_items(related_issues['related_issues'])#convert the dataframe to list\n",
    "cleaned_related_topic_tags = get_items(related_topic_tags['related_topic_tags'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['violation of national legislation',\n",
       " 'corruption, bribery, extortion and money laundering',\n",
       " 'fraud',\n",
       " 'social discrimination',\n",
       " 'human rights abuses and corporate complicity',\n",
       " 'products (health and environmental issues)',\n",
       " 'occupational health and safety issues',\n",
       " 'poor employment conditions',\n",
       " 'supply chain issues',\n",
       " 'impacts on communities',\n",
       " 'impacts on landscapes, ecosystems and biodiversity',\n",
       " 'discrimination in employment',\n",
       " 'misleading communication',\n",
       " 'local pollution',\n",
       " 'climate change, ghg emissions, and global pollution',\n",
       " 'waste issues',\n",
       " 'local participation issues',\n",
       " 'executive compensation issues',\n",
       " 'controversial products and services',\n",
       " 'animal mistreatment',\n",
       " 'tax evasion',\n",
       " 'overuse and wasting of resources',\n",
       " 'forced labor',\n",
       " 'child labor',\n",
       " 'anti-competitive practices',\n",
       " 'freedom of association and collective bargaining',\n",
       " 'tax optimization',\n",
       " 'violation of international standards',\n",
       " 'other esg issues']"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_related_issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cleaned_related_issues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['salaries and benefits',\n",
       " 'migrant labor',\n",
       " 'privacy violations',\n",
       " 'cyberattack',\n",
       " 'negligence',\n",
       " 'racism/racial inequality',\n",
       " 'epidemics/pandemics',\n",
       " 'gender inequality',\n",
       " 'plastics',\n",
       " 'airborne pollutants',\n",
       " 'energy management',\n",
       " 'genetically modified organisms (gmos)',\n",
       " 'asbestos',\n",
       " 'health impact',\n",
       " 'greenhouse gas (ghg) emissions',\n",
       " 'lobbying',\n",
       " 'drones',\n",
       " 'marine/coastal ecosystems',\n",
       " 'access to products and services',\n",
       " 'economic impact',\n",
       " 'tax havens',\n",
       " 'fracking',\n",
       " 'land ecosystems',\n",
       " 'endangered species',\n",
       " 'wastewater management',\n",
       " 'coal-fired power plants',\n",
       " 'mountaintop removal mining',\n",
       " 'deep sea drilling',\n",
       " 'indigenous people',\n",
       " 'protected areas',\n",
       " 'arctic drilling',\n",
       " 'oil sands',\n",
       " 'offshore drilling',\n",
       " 'water management',\n",
       " 'nuclear power',\n",
       " 'water scarcity',\n",
       " 'opioids',\n",
       " 'ship breaking and scrapping',\n",
       " 'land grabbing',\n",
       " 'predatory lending',\n",
       " 'involuntary resettlement',\n",
       " 'hydropower (dams)',\n",
       " 'illegal logging',\n",
       " 'human trafficking',\n",
       " 'tobacco',\n",
       " 'alcohol',\n",
       " 'cluster munitions',\n",
       " 'automatic and semi-automatic weapons',\n",
       " 'conflict minerals',\n",
       " 'animal transportation',\n",
       " 'nuclear weapons',\n",
       " 'sand mining and dredging',\n",
       " 'coral reefs',\n",
       " 'gambling',\n",
       " 'marijuana/cannabis',\n",
       " 'abusive/illegal fishing',\n",
       " 'pornography',\n",
       " 'fur and exotic animal skins',\n",
       " 'soy',\n",
       " 'monocultures',\n",
       " 'genocide/ethnic cleansing',\n",
       " 'depleted uranium munitions',\n",
       " 'security services',\n",
       " 'seabed mining',\n",
       " 'chemical weapons',\n",
       " 'rare earths',\n",
       " 'land mines',\n",
       " 'forest burning',\n",
       " 'biological weapons',\n",
       " 'agricultural commodity speculation',\n",
       " 'high conservation value forests',\n",
       " 'palm oil',\n",
       " 'diamonds']"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_related_topic_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "73"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cleaned_related_topic_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cleaned_related_topic_tags' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(path \u001b[39m+\u001b[39m os\u001b[39m.\u001b[39msep \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39mcleaned_related_issues.pkl\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mwb\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m f3:\n\u001b[1;32m----> 2\u001b[0m     pickle\u001b[39m.\u001b[39mdump(cleaned_related_topic_tags, f3)\n\u001b[0;32m      3\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(path \u001b[39m+\u001b[39m os\u001b[39m.\u001b[39msep \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39mcleaned_related_issues.pkl\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mwb\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m f4:\n\u001b[0;32m      4\u001b[0m     pickle\u001b[39m.\u001b[39mdump(cleaned_related_topic_tags, f4)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'cleaned_related_topic_tags' is not defined"
     ]
    }
   ],
   "source": [
    "with open(path + os.sep + 'cleaned_related_issues.pkl','wb') as f3:\n",
    "    pickle.dump(cleaned_related_topic_tags, f3)\n",
    "with open(path + os.sep + 'cleaned_related_issues.pkl','wb') as f4:\n",
    "    pickle.dump(cleaned_related_topic_tags, f4)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get keywords from news text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_text = re.sub('[^A-Za-z0-9;]+', ' ', i).replace(\"_\", '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenization\n",
    "#stop words removal\n",
    "\n",
    "#pip install transformers\n",
    "\n",
    "import transformers\n",
    "from transformers import BertTokenizerFast\n",
    "#https://huggingface.co/nbroad/ESG-BERT\n",
    "\n",
    "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')\n",
    "\n",
    "def word_tokenization(target_string_list):\n",
    "    tokenized_words = []\n",
    "    for i in target_string_list:\n",
    "        word_tokens = tokenizer.tokenize(i)\n",
    "        tokenized_words.append(word_tokens)\n",
    "    return tokenized_words\n",
    "\n",
    "tokenized_related_issues = word_tokenization(related_issues['related_issues'])#convert the dataframe to list"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
